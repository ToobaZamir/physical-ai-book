<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module3/control" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Chapter 3.3: Bipedal Locomotion &amp; Whole-Body Control (MPC + RL baselines) | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://toobazamir.github.io/physical-ai-book/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://toobazamir.github.io/physical-ai-book/img/social-card.png"><meta data-rh="true" property="og:url" content="https://toobazamir.github.io/physical-ai-book/docs/module3/control"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Chapter 3.3: Bipedal Locomotion &amp; Whole-Body Control (MPC + RL baselines) | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="3.3.1 Introduction: The Grand Challenge of Humanoid Control"><meta data-rh="true" property="og:description" content="3.3.1 Introduction: The Grand Challenge of Humanoid Control"><link data-rh="true" rel="icon" href="/physical-ai-book/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://toobazamir.github.io/physical-ai-book/docs/module3/control"><link data-rh="true" rel="alternate" href="https://toobazamir.github.io/physical-ai-book/docs/module3/control" hreflang="en"><link data-rh="true" rel="alternate" href="https://toobazamir.github.io/physical-ai-book/docs/module3/control" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Chapter 3.3: Bipedal Locomotion & Whole-Body Control (MPC + RL baselines)","item":"https://toobazamir.github.io/physical-ai-book/docs/module3/control"}]}</script><link rel="stylesheet" href="/physical-ai-book/assets/css/styles.7949f0a1.css">
<script src="/physical-ai-book/assets/js/runtime~main.a6dbf511.js" defer="defer"></script>
<script src="/physical-ai-book/assets/js/main.c0fd6e9d.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/physical-ai-book/img/logo.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/physical-ai-book/"><div class="navbar__logo"><img src="/physical-ai-book/img/logo.png" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--light_NVdE" height="40"><img src="/physical-ai-book/img/logo.png" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU" height="40"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a class="navbar__item navbar__link" href="/physical-ai-book/docs/intro">Docs</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/physical-ai-book/docs/intro"><span title="intro" class="linkLabel_WmDU">intro</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical-ai-book/docs/module1/why-ros2"><span title="Module 1: ROS 2 Mastery" class="categoryLinkLabel_W154">Module 1: ROS 2 Mastery</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical-ai-book/docs/module2/gazebo"><span title="Module 2: Digital Twins" class="categoryLinkLabel_W154">Module 2: Digital Twins</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/physical-ai-book/docs/module3/isaac-ros-gems"><span title="Module 3: The AI-Robot Brain" class="categoryLinkLabel_W154">Module 3: The AI-Robot Brain</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module3/isaac-ros-gems"><span title="Chapter 3.1: Isaac ROS GEMs + hardware-accelerated pipelines" class="linkLabel_WmDU">Chapter 3.1: Isaac ROS GEMs + hardware-accelerated pipelines</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module3/perception"><span title="Chapter 3.2: End-to-End Humanoid Perception (people, hands, objects)" class="linkLabel_WmDU">Chapter 3.2: End-to-End Humanoid Perception (people, hands, objects)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/physical-ai-book/docs/module3/control"><span title="Chapter 3.3: Bipedal Locomotion &amp; Whole-Body Control (MPC + RL baselines)" class="linkLabel_WmDU">Chapter 3.3: Bipedal Locomotion &amp; Whole-Body Control (MPC + RL baselines)</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical-ai-book/docs/module4/vla-planning"><span title="Module 4: Vision-Language-Action" class="categoryLinkLabel_W154">Module 4: Vision-Language-Action</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical-ai-book/docs/capstone/"><span title="Capstone Project" class="categoryLinkLabel_W154">Capstone Project</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical-ai-book/docs/appendices/appendix-a"><span title="Appendices" class="categoryLinkLabel_W154">Appendices</span></a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/physical-ai-book/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Module 3: The AI-Robot Brain</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Chapter 3.3: Bipedal Locomotion &amp; Whole-Body Control (MPC + RL baselines)</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Chapter 3.3: Bipedal Locomotion &amp; Whole-Body Control (MPC + RL baselines)</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="331-introduction-the-grand-challenge-of-humanoid-control">3.3.1 Introduction: The Grand Challenge of Humanoid Control<a href="#331-introduction-the-grand-challenge-of-humanoid-control" class="hash-link" aria-label="Direct link to 3.3.1 Introduction: The Grand Challenge of Humanoid Control" title="Direct link to 3.3.1 Introduction: The Grand Challenge of Humanoid Control" translate="no">​</a></h2>
<p>Controlling a bipedal robot to walk, run, jump, and interact with its environment gracefully and robustly is arguably one of the most complex challenges in robotics. Humanoids are inherently unstable systems, constantly battling gravity while requiring a vast range of motion and dynamic stability. This chapter delves into the advanced control methodologies that enable such feats, focusing on Model Predictive Control (MPC) and Reinforcement Learning (RL) as primary tools for achieving both stable locomotion and versatile whole-body control.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="332-foundations-of-bipedal-locomotion">3.3.2 Foundations of Bipedal Locomotion<a href="#332-foundations-of-bipedal-locomotion" class="hash-link" aria-label="Direct link to 3.3.2 Foundations of Bipedal Locomotion" title="Direct link to 3.3.2 Foundations of Bipedal Locomotion" translate="no">​</a></h2>
<p>At the heart of bipedal locomotion control lie fundamental concepts that quantify and manage the robot&#x27;s dynamic stability.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="zero-moment-point-zmp-and-capture-point-cp">Zero Moment Point (ZMP) and Capture Point (CP)<a href="#zero-moment-point-zmp-and-capture-point-cp" class="hash-link" aria-label="Direct link to Zero Moment Point (ZMP) and Capture Point (CP)" title="Direct link to Zero Moment Point (ZMP) and Capture Point (CP)" translate="no">​</a></h3>
<ul>
<li class=""><strong>Zero Moment Point (ZMP):</strong> A critical concept that defines the point on the ground where the net moment of all forces (gravity, inertia) acting on the robot is zero. For stable walking, the ZMP must remain within the robot&#x27;s support polygon (the convex hull of its feet on the ground).</li>
<li class=""><strong>Capture Point (CP):</strong> An evolution of ZMP, the CP indicates where the robot&#x27;s center of pressure needs to be to prevent falling, given its current state. It helps predict and manage stability during dynamic motions.</li>
</ul>
<p><strong>Diagram Placeholder: ZMP and Capture Point Concepts in Bipedal Walking</strong>
<em>(A diagram illustrating a bipedal robot in motion, showing the Center of Mass (CoM) trajectory, the Support Polygon, and the projection of the ZMP and CP onto the ground plane.)</em></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="walking-pattern-generation">Walking Pattern Generation<a href="#walking-pattern-generation" class="hash-link" aria-label="Direct link to Walking Pattern Generation" title="Direct link to Walking Pattern Generation" translate="no">​</a></h3>
<p>The process of generating a stable and desired walking motion for a humanoid involves planning footstep locations, body trajectories, and ensuring dynamic balance. This can be achieved through various methods, from pre-defined gait patterns to real-time trajectory optimization.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="333-model-predictive-control-mpc-for-humanoids">3.3.3 Model Predictive Control (MPC) for Humanoids<a href="#333-model-predictive-control-mpc-for-humanoids" class="hash-link" aria-label="Direct link to 3.3.3 Model Predictive Control (MPC) for Humanoids" title="Direct link to 3.3.3 Model Predictive Control (MPC) for Humanoids" translate="no">​</a></h2>
<p>Model Predictive Control (MPC) is an optimization-based control strategy that uses a model of the system to predict its future behavior over a finite horizon. It then calculates a sequence of control inputs that minimizes a cost function (e.g., energy consumption, deviation from desired trajectory) while satisfying constraints (e.g., joint limits, ZMP within support polygon).</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="mpc-principles">MPC Principles:<a href="#mpc-principles" class="hash-link" aria-label="Direct link to MPC Principles:" title="Direct link to MPC Principles:" translate="no">​</a></h3>
<ul>
<li class=""><strong>Predictive Model:</strong> A mathematical representation of the robot&#x27;s dynamics.</li>
<li class=""><strong>Cost Function:</strong> Defines the control objectives (what to optimize).</li>
<li class=""><strong>Constraints:</strong> Physical limits of the robot and environmental boundaries.</li>
<li class=""><strong>Optimization:</strong> A solver finds the optimal control sequence. Only the first control action is applied, and the process repeats at the next time step (receding horizon).</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="application-to-whole-body-control-wbc">Application to Whole-Body Control (WBC)<a href="#application-to-whole-body-control-wbc" class="hash-link" aria-label="Direct link to Application to Whole-Body Control (WBC)" title="Direct link to Application to Whole-Body Control (WBC)" translate="no">​</a></h3>
<p>MPC is particularly powerful for Whole-Body Control (WBC) of humanoids, where it can simultaneously optimize for multiple tasks such as:</p>
<ul>
<li class="">Maintaining balance and stability.</li>
<li class="">Tracking desired CoM trajectories.</li>
<li class="">Achieving end-effector poses for manipulation.</li>
<li class="">Avoiding joint limits and self-collisions.</li>
</ul>
<p><strong>Conceptual Example: MPC Formulation for Humanoid Balance</strong></p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Conceptual pseudo-code for an MPC problem formulation for humanoid balance</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">HumanoidMPC</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> robot_model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> dt</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> prediction_horizon</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> robot_model </span><span class="token comment" style="color:#999988;font-style:italic"># Simplified model of humanoid dynamics</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">dt </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> dt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">horizon </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> prediction_horizon</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Define state (CoM position, velocity, etc.) and control inputs (joint torques/forces)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">solve_mpc</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> current_state</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> desired_com_traj</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> foot_contact_forces</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        Formulates and solves an MPC problem for the humanoid.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Define optimization variables (future states and control inputs)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Define cost function:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic">#   - Penalize deviation from desired CoM trajectory</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic">#   - Penalize large joint torques/forces</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic">#   - Penalize ZMP violating support polygon</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Define constraints:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic">#   - Robot dynamics equations</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic">#   - Joint limits, velocity limits</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic">#   - Force limits (e.g., maximum ground reaction force)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic">#   - Contact constraints (foot on ground)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Use an optimization solver (e.g., quadratic programming)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># optimal_controls = solver.solve(cost_function, constraints)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Return the first optimal control action</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> optimal_control_action</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># In a control loop:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># current_state = get_robot_state()</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># desired_trajectory = planner.get_desired_trajectory()</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># mpc_solver = HumanoidMPC(...)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># control_action = mpc_solver.solve_mpc(current_state, desired_trajectory, contact_info)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># apply_control_action(control_action)</span><br></span></code></pre></div></div>
<p><em>Description:</em> This conceptual class illustrates how an MPC problem for a humanoid robot would be formulated, defining a cost function and constraints to achieve stable and goal-oriented movements.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="334-reinforcement-learning-rl-baselines-for-locomotion">3.3.4 Reinforcement Learning (RL) Baselines for Locomotion<a href="#334-reinforcement-learning-rl-baselines-for-locomotion" class="hash-link" aria-label="Direct link to 3.3.4 Reinforcement Learning (RL) Baselines for Locomotion" title="Direct link to 3.3.4 Reinforcement Learning (RL) Baselines for Locomotion" translate="no">​</a></h2>
<p>Reinforcement Learning (RL) has emerged as a powerful paradigm for learning complex behaviors, including bipedal locomotion, often surpassing traditional control methods in adaptability and robustness.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="rl-basics">RL Basics:<a href="#rl-basics" class="hash-link" aria-label="Direct link to RL Basics:" title="Direct link to RL Basics:" translate="no">​</a></h3>
<ul>
<li class=""><strong>Agent:</strong> The humanoid robot learning to walk.</li>
<li class=""><strong>Environment:</strong> The simulation (or real world) where the robot acts.</li>
<li class=""><strong>State:</strong> The robot&#x27;s current configuration (joint angles, velocities, IMU readings) and often environmental observations.</li>
<li class=""><strong>Action:</strong> The control commands (e.g., joint torques, desired positions) sent to the robot.</li>
<li class=""><strong>Reward:</strong> A scalar signal from the environment indicating how well the agent is performing a desired task (e.g., positive for forward motion, negative for falling).</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="learning-gaits-and-policies">Learning Gaits and Policies:<a href="#learning-gaits-and-policies" class="hash-link" aria-label="Direct link to Learning Gaits and Policies:" title="Direct link to Learning Gaits and Policies:" translate="no">​</a></h3>
<p>RL algorithms train a neural network (the policy) to map states to optimal actions by maximizing cumulative reward. This can involve:</p>
<ul>
<li class=""><strong>Learning from Scratch:</strong> Discovering walking gaits purely through trial and error.</li>
<li class=""><strong>Refining Existing Gaits:</strong> Improving the robustness or efficiency of pre-designed gaits.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="common-rl-algorithms-conceptual">Common RL Algorithms (Conceptual):<a href="#common-rl-algorithms-conceptual" class="hash-link" aria-label="Direct link to Common RL Algorithms (Conceptual):" title="Direct link to Common RL Algorithms (Conceptual):" translate="no">​</a></h3>
<ul>
<li class=""><strong>Proximal Policy Optimization (PPO):</strong> A popular policy gradient method known for its stability and good performance in robotics tasks.</li>
<li class=""><strong>Soft Actor-Critic (SAC):</strong> An off-policy algorithm that optimizes a stochastic policy, often achieving state-of-the-art results in continuous control.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="sim-to-real-transfer-for-rl-policies">Sim-to-Real Transfer for RL Policies:<a href="#sim-to-real-transfer-for-rl-policies" class="hash-link" aria-label="Direct link to Sim-to-Real Transfer for RL Policies:" title="Direct link to Sim-to-Real Transfer for RL Policies:" translate="no">​</a></h3>
<p>A key challenge for RL is transferring policies learned in simulation to the real world. Techniques like <strong>domain randomization</strong> (varying simulation parameters during training) help make policies more robust to real-world discrepancies.</p>
<p>[QR Code: Link to a humanoid locomotion RL framework, e.g., Isaac Gym or DeepMimic research]</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="335-whole-body-control-wbc-integration">3.3.5 Whole-Body Control (WBC) Integration<a href="#335-whole-body-control-wbc-integration" class="hash-link" aria-label="Direct link to 3.3.5 Whole-Body Control (WBC) Integration" title="Direct link to 3.3.5 Whole-Body Control (WBC) Integration" translate="no">​</a></h2>
<p>Modern humanoid control often combines the strengths of various techniques within a Whole-Body Control (WBC) framework. WBC seeks to coordinate all of the robot&#x27;s degrees of freedom to achieve multiple tasks simultaneously, often prioritizing them.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="hierarchical-control-structures">Hierarchical Control Structures:<a href="#hierarchical-control-structures" class="hash-link" aria-label="Direct link to Hierarchical Control Structures:" title="Direct link to Hierarchical Control Structures:" translate="no">​</a></h3>
<p>Control systems for humanoids are frequently hierarchical:</p>
<ul>
<li class=""><strong>High-Level:</strong> Task planning, gait generation (e.g., footstep placement).</li>
<li class=""><strong>Mid-Level:</strong> MPC or RL policies generating CoM trajectories and desired contact forces.</li>
<li class=""><strong>Low-Level:</strong> Joint-level controllers translating desired torques/positions into motor commands.</li>
</ul>
<p><strong>Diagram Placeholder: Hierarchical Humanoid Control Architecture</strong>
<em>(A layered diagram showing high-level planners, mid-level whole-body controllers (MPC/RL), and low-level joint controllers.)</em></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="task-prioritization">Task Prioritization:<a href="#task-prioritization" class="hash-link" aria-label="Direct link to Task Prioritization:" title="Direct link to Task Prioritization:" translate="no">​</a></h3>
<p>WBC allows for dynamic prioritization of tasks. For example, maintaining balance might have higher priority than achieving a precise end-effector position.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="336-conclusion">3.3.6 Conclusion<a href="#336-conclusion" class="hash-link" aria-label="Direct link to 3.3.6 Conclusion" title="Direct link to 3.3.6 Conclusion" translate="no">​</a></h2>
<p>Bipedal locomotion and whole-body control are at the forefront of humanoid robotics research. The combination of model-based approaches like MPC with data-driven methods like RL offers powerful solutions for generating robust, agile, and adaptable movements. As these techniques mature, we move closer to a future where humanoids can navigate and interact with the world with unprecedented dexterity and intelligence.</p></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/physical-ai-book/docs/module3/perception"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Chapter 3.2: End-to-End Humanoid Perception (people, hands, objects)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/physical-ai-book/docs/module4/vla-planning"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Chapter 4.1: Voice → LLM → Task Plan → ROS 2 Actions</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#331-introduction-the-grand-challenge-of-humanoid-control" class="table-of-contents__link toc-highlight">3.3.1 Introduction: The Grand Challenge of Humanoid Control</a></li><li><a href="#332-foundations-of-bipedal-locomotion" class="table-of-contents__link toc-highlight">3.3.2 Foundations of Bipedal Locomotion</a><ul><li><a href="#zero-moment-point-zmp-and-capture-point-cp" class="table-of-contents__link toc-highlight">Zero Moment Point (ZMP) and Capture Point (CP)</a></li><li><a href="#walking-pattern-generation" class="table-of-contents__link toc-highlight">Walking Pattern Generation</a></li></ul></li><li><a href="#333-model-predictive-control-mpc-for-humanoids" class="table-of-contents__link toc-highlight">3.3.3 Model Predictive Control (MPC) for Humanoids</a><ul><li><a href="#mpc-principles" class="table-of-contents__link toc-highlight">MPC Principles:</a></li><li><a href="#application-to-whole-body-control-wbc" class="table-of-contents__link toc-highlight">Application to Whole-Body Control (WBC)</a></li></ul></li><li><a href="#334-reinforcement-learning-rl-baselines-for-locomotion" class="table-of-contents__link toc-highlight">3.3.4 Reinforcement Learning (RL) Baselines for Locomotion</a><ul><li><a href="#rl-basics" class="table-of-contents__link toc-highlight">RL Basics:</a></li><li><a href="#learning-gaits-and-policies" class="table-of-contents__link toc-highlight">Learning Gaits and Policies:</a></li><li><a href="#common-rl-algorithms-conceptual" class="table-of-contents__link toc-highlight">Common RL Algorithms (Conceptual):</a></li><li><a href="#sim-to-real-transfer-for-rl-policies" class="table-of-contents__link toc-highlight">Sim-to-Real Transfer for RL Policies:</a></li></ul></li><li><a href="#335-whole-body-control-wbc-integration" class="table-of-contents__link toc-highlight">3.3.5 Whole-Body Control (WBC) Integration</a><ul><li><a href="#hierarchical-control-structures" class="table-of-contents__link toc-highlight">Hierarchical Control Structures:</a></li><li><a href="#task-prioritization" class="table-of-contents__link toc-highlight">Task Prioritization:</a></li></ul></li><li><a href="#336-conclusion" class="table-of-contents__link toc-highlight">3.3.6 Conclusion</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/ToobaZamir/physical-ai-book" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">© 2025 Tooba Zamir — Physical AI & Humanoid Robotics.</div></div></div></footer></div>
</body>
</html>