"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[400],{5058:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"appendices/appendix-e","title":"Appendix E: Glossary of Key Terms","description":"E.1 Introduction: Clarifying the Robotics Lexicon","source":"@site/docs/appendices/appendix-e.md","sourceDirName":"appendices","slug":"/appendices/appendix-e","permalink":"/physical-ai-book/docs/appendices/appendix-e","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Appendix D: Advanced Topics in Robot Learning","permalink":"/physical-ai-book/docs/appendices/appendix-d"}}');var r=i(4848),s=i(8453);const o={},a="Appendix E: Glossary of Key Terms",c={},l=[{value:"E.1 Introduction: Clarifying the Robotics Lexicon",id:"e1-introduction-clarifying-the-robotics-lexicon",level:2},{value:"E.2 Glossary Entries (Alphabetical)",id:"e2-glossary-entries-alphabetical",level:2}];function d(e){const n={h1:"h1",h2:"h2",header:"header",p:"p",strong:"strong",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"appendix-e-glossary-of-key-terms",children:"Appendix E: Glossary of Key Terms"})}),"\n",(0,r.jsx)(n.h2,{id:"e1-introduction-clarifying-the-robotics-lexicon",children:"E.1 Introduction: Clarifying the Robotics Lexicon"}),"\n",(0,r.jsx)(n.p,{children:"The fields of Physical AI and Humanoid Robotics are rich with specialized terminology, drawing from diverse disciplines such as computer science, engineering, and cognitive science. This glossary serves as a quick reference for essential terms and concepts encountered throughout this book, providing concise definitions to clarify jargon and reinforce understanding for readers of all levels."}),"\n",(0,r.jsx)(n.h2,{id:"e2-glossary-entries-alphabetical",children:"E.2 Glossary Entries (Alphabetical)"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Affordance:"}),' The perceived functional properties of an object or environment that suggest how it can be interacted with (e.g., a "handle" affords "grasping").']}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Agent (RL):"})," In Reinforcement Learning, the entity that performs actions in an environment to achieve a goal by maximizing cumulative reward."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Bill of Materials (BOM):"})," A comprehensive list of all raw materials, components, and sub-assemblies required to manufacture a product, along with their quantities."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Capstone Project:"})," A culminating project that integrates knowledge and skills acquired throughout a course or program, often involving real-world problem-solving."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Capture Point (CP):"})," A dynamic stability metric used in bipedal locomotion, indicating the point where the robot's center of pressure must be to prevent falling."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"CUDA:"})," (Compute Unified Device Architecture) NVIDIA's parallel computing platform and programming model that enables significant performance increases by harnessing the power of the GPU."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Data Distribution Service (DDS):"})," A middleware standard that provides a scalable, real-time, and reliable mechanism for publishing and subscribing to data in distributed systems, forming the communication backbone of ROS 2."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Digital Twin:"})," A virtual replica of a physical asset, process, or system that serves as a living model for real-time understanding, prediction, and optimization."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Domain Randomization:"})," A technique in robot learning where various parameters of a simulation (e.g., textures, lighting, physics properties) are randomized during training to improve the transferability of policies to the real world (sim-to-real)."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Grasping:"})," The act by which a robot's end-effector (gripper/hand) establishes contact with and secures an object for manipulation."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Hardware Acceleration:"})," The use of specialized computer hardware (e.g., GPUs, FPGAs, NPUs) to perform computational tasks more efficiently than a general-purpose CPU, often crucial for real-time performance in robotics."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Human-Robot Interaction (HRI):"})," The study of interactions between humans and robots, focusing on designing robots that can interact effectively, safely, and naturally with people."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"IMU (Inertial Measurement Unit):"})," An electronic device that measures and reports a body's specific force, angular rate, and sometimes magnetic field surrounding the body, using a combination of accelerometers, gyroscopes, and magnetometers."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Isaac ROS GEMs:"})," GPU-Enabled Modules from NVIDIA Isaac ROS, which are hardware-accelerated, optimized ROS 2 packages designed to speed up perception and AI tasks on NVIDIA GPUs."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Isaac Sim:"})," NVIDIA's scalable robotics simulation application and synthetic data generation tool, built on the Omniverse platform, providing high-fidelity, physically accurate virtual environments."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Jetson (NVIDIA):"})," A series of compact, high-performance, low-power embedded computing boards from NVIDIA designed for AI and deep learning applications at the edge."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Launch File (ROS 2):"})," A Python or XML script used in ROS 2 to start, configure, and manage multiple nodes, parameters, and other ROS 2 entities, orchestrating a robotic system."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"LiDAR:"})," (Light Detection and Ranging) A remote sensing method that uses pulsed laser light to measure ranges (variable distances) to the Earth. In robotics, it's used for 3D mapping and obstacle detection."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Large Language Model (LLM):"})," A type of artificial intelligence model trained on vast amounts of text data, capable of understanding, generating, and processing human language."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Model Predictive Control (MPC):"})," An advanced method of process control that uses a dynamic model of the system to predict future behavior and optimize control actions over a finite time horizon."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Multi-Agent Reinforcement Learning (MARL):"})," An extension of Reinforcement Learning that studies how multiple learning agents interact within a shared environment to achieve individual or collective goals."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Node (ROS 2):"})," An executable process in ROS 2 that performs computation (e.g., a sensor driver, a controller, an algorithm). Multiple nodes can run concurrently and communicate with each other."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Omniverse (NVIDIA):"})," A platform for connecting and building custom 3D pipelines and simulating large-scale virtual worlds, based on Universal Scene Description (USD)."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Perception:"})," The robot's ability to sense, interpret, and understand its environment using data from various sensors (e.g., cameras, LiDAR, tactile sensors)."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Reinforcement Learning (RL):"})," A machine learning paradigm where an agent learns to make decisions by performing actions in an environment to maximize a cumulative reward signal."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"ROS 2:"})," (Robot Operating System 2) A flexible framework for writing robot software, providing standard operating system-like services such as hardware abstraction, low-level device control, implementation of common functionality, and message-passing between processes."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Sim-to-Real Transfer:"}),' The process of transferring policies or skills learned in a simulated environment to a physical robot in the real world, often a challenging task due to the "reality gap."']}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"SDF (Simulation Description Format):"})," An XML-based file format used in Gazebo and other simulators to describe robots, static and dynamic objects, and environments in a standardized way."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Synthetic Data:"})," Data that is artificially generated rather than obtained from real-world measurements, often used to train machine learning models, particularly in robotics where real data collection can be costly or dangerous."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Topic (ROS 2):"})," An anonymous data stream in ROS 2 where nodes publish messages and other nodes subscribe to receive them, enabling asynchronous communication."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Universal Scene Description (USD):"})," An open-source, extensible framework developed by Pixar for robust interchange and composition of 3D data, acting as a universal format for virtual content."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"URDF (Unified Robot Description Format):"})," An XML file format used in ROS to describe all elements of a robot, including its kinematic and dynamic properties, visual appearance, and collision models."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Vision-Language-Action (VLA):"})," A paradigm in robotics and AI where a robot uses visual input and natural language commands (often processed by LLMs) to plan and execute physical actions in an environment."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Whole-Body Control (WBC):"})," A control methodology for highly redundant robots (like humanoids) that simultaneously coordinates all degrees of freedom to achieve multiple tasks while respecting physical constraints."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Zero Moment Point (ZMP):"})," A point on the ground about which the sum of all moments of active forces is zero, indicating the location where the robot's resultant ground reaction force must act for static or dynamic stability."]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>a});var t=i(6540);const r={},s=t.createContext(r);function o(e){const n=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);